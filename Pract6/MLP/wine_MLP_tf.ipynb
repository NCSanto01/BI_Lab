{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cdbcef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Configuraci√≥n warnings\n",
    "# ------------------------------------------------------------------------------\n",
    "import warnings\n",
    "#warnings.filterwarnings('once')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2922dca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Loading\n",
    "\n",
    "df = pd.read_csv('winequality-red.csv')\n",
    " \n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a045b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae1231ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting training and test datasets\n",
    "import tensorflow as tf\n",
    "\n",
    "# 75% of the data is selected\n",
    "train_df = df.sample(frac=0.75, random_state=4) \n",
    "\n",
    "# it drops the training data\n",
    "# from the original dataframe\n",
    "val_df = df.drop(train_df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08ad7933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "\n",
    "# calling to (0,1) range\n",
    "max_val = train_df.max(axis= 0)\n",
    "min_val = train_df.min(axis= 0)\n",
    "\n",
    "range = max_val - min_val\n",
    "train_df = (train_df - min_val)/(range)\n",
    "\n",
    "val_df = (val_df- min_val)/range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dea8e505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's separate the targets and labels\n",
    "X_train = train_df.drop('quality',axis=1)\n",
    "X_val = val_df.drop('quality',axis=1)\n",
    "y_train = train_df['quality']\n",
    "y_val = val_df['quality']\n",
    "\n",
    "# We'll need to pass the shape\n",
    "# of features/inputs as an argument\n",
    "# in our model, so let's define a variable \n",
    "# to save it.\n",
    "input_shape = [X_train.shape[1]]\n",
    "\n",
    "input_shape  # number of features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d95d8487",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train-3, num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e27f1224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bca85b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout, BatchNormalization\n",
    "from keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b0203a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 4096)              49152     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 4,934,278\n",
      "Trainable params: 4,934,278\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(Dense(4096, input_shape= (X_train.shape[1],), activation='relu')) #input layer with 64 neurons\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024,activation= 'relu'))\n",
    "model.add(Dense(512,activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256,activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "model.add(Dense(6, activation='softmax')) #output layer with 1 neuron \n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Nadam(4e-4),metrics ='Precision')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71ab3a04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7/7 [==============================] - 2s 112ms/step - loss: 1.1394 - precision: 1.0000 - val_loss: 0.1245 - val_precision: 0.9872\n",
      "Epoch 2/60\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 0.0682 - precision: 0.9955 - val_loss: 0.1120 - val_precision: 0.9872\n",
      "Epoch 3/60\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 0.0547 - precision: 0.9955 - val_loss: 0.1184 - val_precision: 0.9872\n",
      "Epoch 4/60\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0558 - precision: 0.9955 - val_loss: 0.1032 - val_precision: 0.9872\n",
      "Epoch 5/60\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 0.0460 - precision: 0.9955 - val_loss: 0.0877 - val_precision: 0.9872\n",
      "Epoch 6/60\n",
      "7/7 [==============================] - 0s 73ms/step - loss: 0.0374 - precision: 0.9955 - val_loss: 0.0801 - val_precision: 0.9872\n",
      "Epoch 7/60\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 0.0381 - precision: 0.9955 - val_loss: 0.0796 - val_precision: 0.9872\n",
      "Epoch 8/60\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 0.0425 - precision: 0.9955 - val_loss: 0.0752 - val_precision: 0.9872\n",
      "Epoch 9/60\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 0.0362 - precision: 0.9955 - val_loss: 0.0720 - val_precision: 0.9872\n",
      "Epoch 10/60\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 0.0358 - precision: 0.9955 - val_loss: 0.0714 - val_precision: 0.9872\n",
      "Epoch 11/60\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0351 - precision: 0.9955 - val_loss: 0.0707 - val_precision: 0.9872\n",
      "Epoch 12/60\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0304 - precision: 0.9955 - val_loss: 0.0673 - val_precision: 0.9872\n",
      "Epoch 13/60\n",
      "7/7 [==============================] - 0s 73ms/step - loss: 0.0320 - precision: 0.9955 - val_loss: 0.0712 - val_precision: 0.9872\n",
      "Epoch 14/60\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 0.0337 - precision: 0.9955 - val_loss: 0.0673 - val_precision: 0.9872\n",
      "Epoch 15/60\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 0.0360 - precision: 0.9955 - val_loss: 0.0649 - val_precision: 0.9872\n",
      "Epoch 16/60\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.0295 - precision: 0.9955 - val_loss: 0.0661 - val_precision: 0.9872\n",
      "Epoch 17/60\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 0.0270 - precision: 0.9955 - val_loss: 0.0700 - val_precision: 0.9872\n",
      "Epoch 18/60\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 0.0321 - precision: 0.9955 - val_loss: 0.0638 - val_precision: 0.9872\n",
      "Epoch 19/60\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 0.0303 - precision: 0.9955 - val_loss: 0.0632 - val_precision: 0.9872\n",
      "Epoch 20/60\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 0.0305 - precision: 0.9955 - val_loss: 0.0601 - val_precision: 0.9872\n",
      "Epoch 21/60\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 0.0274 - precision: 0.9955 - val_loss: 0.0588 - val_precision: 0.9872\n",
      "Epoch 22/60\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 0.0262 - precision: 0.9955 - val_loss: 0.0727 - val_precision: 0.9872\n",
      "Epoch 23/60\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 0.0299 - precision: 0.9955 - val_loss: 0.0630 - val_precision: 0.9872\n",
      "Epoch 24/60\n",
      "7/7 [==============================] - 0s 73ms/step - loss: 0.0284 - precision: 0.9955 - val_loss: 0.0675 - val_precision: 0.9872\n",
      "Epoch 25/60\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 0.0309 - precision: 0.9955 - val_loss: 0.0647 - val_precision: 0.9872\n",
      "Epoch 26/60\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.0277 - precision: 0.9955 - val_loss: 0.0712 - val_precision: 0.9872\n",
      "Epoch 27/60\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 0.0287 - precision: 0.9955 - val_loss: 0.0586 - val_precision: 0.9872\n",
      "Epoch 28/60\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 0.0268 - precision: 0.9955 - val_loss: 0.0565 - val_precision: 0.9872\n",
      "Epoch 29/60\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 0.0215 - precision: 0.9955 - val_loss: 0.0609 - val_precision: 0.9872\n",
      "Epoch 30/60\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0289 - precision: 0.9966 - val_loss: 0.0657 - val_precision: 0.9872\n",
      "Epoch 31/60\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 0.0246 - precision: 0.9955 - val_loss: 0.0548 - val_precision: 0.9872\n",
      "Epoch 32/60\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 0.0192 - precision: 0.9955 - val_loss: 0.0603 - val_precision: 0.9872\n",
      "Epoch 33/60\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 0.0243 - precision: 0.9955 - val_loss: 0.0667 - val_precision: 0.9872\n",
      "Epoch 34/60\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0226 - precision: 0.9955 - val_loss: 0.0635 - val_precision: 0.9872\n",
      "Epoch 35/60\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0210 - precision: 0.9955 - val_loss: 0.0508 - val_precision: 0.9872\n",
      "Epoch 36/60\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.0196 - precision: 0.9966 - val_loss: 0.0713 - val_precision: 0.9872\n",
      "Epoch 37/60\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0328 - precision: 0.9955 - val_loss: 0.0643 - val_precision: 0.9872\n",
      "Epoch 38/60\n",
      "7/7 [==============================] - 1s 77ms/step - loss: 0.0212 - precision: 0.9955 - val_loss: 0.0626 - val_precision: 0.9872\n",
      "Epoch 39/60\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0219 - precision: 0.9955 - val_loss: 0.0716 - val_precision: 0.9872\n",
      "Epoch 40/60\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0174 - precision: 0.9955 - val_loss: 0.0545 - val_precision: 0.9872\n",
      "Epoch 41/60\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0183 - precision: 0.9955 - val_loss: 0.0634 - val_precision: 0.9872\n",
      "Epoch 42/60\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 0.0167 - precision: 0.9955 - val_loss: 0.0743 - val_precision: 0.9872\n",
      "Epoch 43/60\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0167 - precision: 0.9955 - val_loss: 0.0836 - val_precision: 0.9872\n",
      "Epoch 44/60\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 0.0198 - precision: 0.9966 - val_loss: 0.0589 - val_precision: 0.9872\n",
      "Epoch 45/60\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 0.0170 - precision: 0.9955 - val_loss: 0.0679 - val_precision: 0.9872\n",
      "Epoch 46/60\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 0.0147 - precision: 0.9955 - val_loss: 0.0850 - val_precision: 0.9872\n",
      "Epoch 47/60\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0194 - precision: 0.9955 - val_loss: 0.0564 - val_precision: 0.9872\n",
      "Epoch 48/60\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 0.0141 - precision: 0.9955 - val_loss: 0.0768 - val_precision: 0.9872\n",
      "Epoch 49/60\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 0.0184 - precision: 0.9955 - val_loss: 0.0542 - val_precision: 0.9872\n",
      "Epoch 50/60\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.0133 - precision: 0.9966 - val_loss: 0.0948 - val_precision: 0.9872\n",
      "Epoch 51/60\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 0.0130 - precision: 0.9955 - val_loss: 0.0688 - val_precision: 0.9872\n",
      "Epoch 52/60\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0169 - precision: 0.9955 - val_loss: 0.0821 - val_precision: 0.9872\n",
      "Epoch 53/60\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 0.0127 - precision: 0.9955 - val_loss: 0.0629 - val_precision: 0.9872\n",
      "Epoch 54/60\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 0.0192 - precision: 0.9955 - val_loss: 0.0591 - val_precision: 0.9872\n",
      "Epoch 55/60\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 0.0146 - precision: 0.9966 - val_loss: 0.0554 - val_precision: 0.9872\n",
      "Epoch 56/60\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.0142 - precision: 0.9966 - val_loss: 0.0680 - val_precision: 0.9872\n",
      "Epoch 57/60\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.0118 - precision: 0.9966 - val_loss: 0.0827 - val_precision: 0.9872\n",
      "Epoch 58/60\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.0118 - precision: 0.9955 - val_loss: 0.0709 - val_precision: 0.9872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/60\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 0.0161 - precision: 0.9966 - val_loss: 0.0995 - val_precision: 0.9872\n",
      "Epoch 60/60\n",
      "7/7 [==============================] - 1s 81ms/step - loss: 0.0172 - precision: 0.9966 - val_loss: 0.0715 - val_precision: 0.9872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14ae1ce2a60>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_split = 0.26,batch_size =128,epochs = 60)#,callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a0ea396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0 Importance 0.087237686\n",
      "Feature 1 Importance 0.08464585\n",
      "Feature 2 Importance 0.09019297\n",
      "Feature 3 Importance 0.08756355\n",
      "Feature 4 Importance 0.08763155\n",
      "Feature 5 Importance 0.08847035\n",
      "Feature 6 Importance 0.096224725\n",
      "Feature 7 Importance 0.082624905\n",
      "Feature 8 Importance 0.08724287\n",
      "Feature 9 Importance 0.08879922\n",
      "Feature 10 Importance 0.09277625\n"
     ]
    }
   ],
   "source": [
    "# Get the weights of the first layer\n",
    "weights = model.layers[0].get_weights()[0]\n",
    "\n",
    "# Get the absolute values of the weights\n",
    "importances = np.abs(weights)\n",
    "\n",
    "# Normalize the importances\n",
    "importances = importances / importances.sum(axis=0)\n",
    "\n",
    "# Print the importances of each feature\n",
    "for i, importance in enumerate(importances):\n",
    "    print(\"Feature\", i, \"Importance\", np.median(importance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c60f90d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([4 4 4 ... 4 4 4], shape=(1199,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "prediction_train = tf.argmax( model.predict(X_train), axis=1) \n",
    "print(y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f1e738a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4], shape=(400,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "prediction_test = tf.argmax( model.predict(X_val), axis=1) \n",
    "print(prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27bda424",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'classes_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-c1200b29ae22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Confusion Matrix for Winequality Dataset - TRAIN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'classes_'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "fig = plot_confusion_matrix(model, X_train, y_train, display_labels=model.classes_)\n",
    "fig.figure_.suptitle(\"Confusion Matrix for Winequality Dataset - TRAIN\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865ba15f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92064bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb94335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79dd262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f89b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/ashishkumarak/wine-quality-prediction-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdb3b46c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kerastuner'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-f7ee1b906d37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkerastuner\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomSearch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkerastuner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kerastuner'"
     ]
    }
   ],
   "source": [
    "from kerastuner import RandomSearch\n",
    "import kerastuner\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(units=hp.Int('units', min_value=2048, max_value=8116, step=512), activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(units=hp.Int('units', min_value=2048, max_value=4096, step=512), activation='relu')) \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=hp.Int('units', min_value=512, max_value=1024, step=256),activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=hp.Int('units', min_value=256, max_value=512, step=64),activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256,activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128,activation = 'relu'))\n",
    "    model.add(Dense(6, activation='softmax')) \n",
    "    model.compile(optimizer=tf.keras.optimizers.Nadam(hp.Choice('learning_rate', values=[1e-3, 4e-4, 7e-4,3e-5])),\n",
    "                  loss=tfa.losses.SigmoidFocalCrossEntropy(), metrics=[tfa.metrics.CohenKappa(num_classes = 6,weightage = 'quadratic')])\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(build_model,    objective=kerastuner.Objective(\"val_loss\", direction=\"min\"),\n",
    "     max_trials=10, project_name='intro_to_kt')\n",
    "tuner.search(x=X_train, y=y_train, epochs=25,batch_size = 128, validation_split = 0.26)\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274fc15f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab30d99c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5735c0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                768       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 4,993\n",
      "Trainable params: 4,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model building\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Dense(units=64, activation='relu',input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "\n",
    "\n",
    "# after you create your model it's\n",
    "# always a good habit to print out it's summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c0d88f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam optimizer works pretty well for\n",
    "# all kinds of problems and is a good starting point\n",
    "model.compile(optimizer='adam', \n",
    "            # MAE error is good for numerical predictions\n",
    "            loss='mae') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65d5b009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.7232 - val_loss: 0.5812\n",
      "Epoch 2/15\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5115 - val_loss: 0.3969\n",
      "Epoch 3/15\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3357 - val_loss: 0.2380\n",
      "Epoch 4/15\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1893 - val_loss: 0.1400\n",
      "Epoch 5/15\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1410 - val_loss: 0.1464\n",
      "Epoch 6/15\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1539 - val_loss: 0.1474\n",
      "Epoch 7/15\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1436 - val_loss: 0.1306\n",
      "Epoch 8/15\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1274 - val_loss: 0.1210\n",
      "Epoch 9/15\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1203 - val_loss: 0.1162\n",
      "Epoch 10/15\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1166 - val_loss: 0.1120\n",
      "Epoch 11/15\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1126 - val_loss: 0.1086\n",
      "Epoch 12/15\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1095 - val_loss: 0.1069\n",
      "Epoch 13/15\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1066 - val_loss: 0.1050\n",
      "Epoch 14/15\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1059 - val_loss: 0.1043\n",
      "Epoch 15/15\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1044 - val_loss: 0.1043\n"
     ]
    }
   ],
   "source": [
    "losses = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                # it will use 'batch_size' number\n",
    "                # of examples per example\n",
    "                batch_size=256, \n",
    "                epochs=15, # total epoch\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e0e9996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42174911],\n",
       "       [0.519015  ],\n",
       "       [0.4368481 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will pass the first 3 rows of features\n",
    "# of our data as input to make predictions\n",
    "model.predict(X_val.iloc[0:3, :])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50dd92c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.4\n",
       "9     0.4\n",
       "12    0.4\n",
       "Name: quality, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.iloc[0:3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c17e1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95256e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.723186</td>\n",
       "      <td>0.581182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.511549</td>\n",
       "      <td>0.396933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.335691</td>\n",
       "      <td>0.237998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.189284</td>\n",
       "      <td>0.139953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.140986</td>\n",
       "      <td>0.146401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.153920</td>\n",
       "      <td>0.147429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.143588</td>\n",
       "      <td>0.130583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.127368</td>\n",
       "      <td>0.121019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.120343</td>\n",
       "      <td>0.116173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.116616</td>\n",
       "      <td>0.112020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.112550</td>\n",
       "      <td>0.108575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.109515</td>\n",
       "      <td>0.106950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.106589</td>\n",
       "      <td>0.105050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.105873</td>\n",
       "      <td>0.104251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.104369</td>\n",
       "      <td>0.104252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  val_loss\n",
       "0   0.723186  0.581182\n",
       "1   0.511549  0.396933\n",
       "2   0.335691  0.237998\n",
       "3   0.189284  0.139953\n",
       "4   0.140986  0.146401\n",
       "5   0.153920  0.147429\n",
       "6   0.143588  0.130583\n",
       "7   0.127368  0.121019\n",
       "8   0.120343  0.116173\n",
       "9   0.116616  0.112020\n",
       "10  0.112550  0.108575\n",
       "11  0.109515  0.106950\n",
       "12  0.106589  0.105050\n",
       "13  0.105873  0.104251\n",
       "14  0.104369  0.104252"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b0e1820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c183144b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ff0b02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
